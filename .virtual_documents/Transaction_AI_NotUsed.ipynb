


# Importando as bibliotecas necessárias
import joblib
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score


transactions_df = pd.read_csv('transactions_1.csv')

transactions_df.head(3)





# Pivotando os dados para que cada status seja uma coluna
pivot_df = transactions_df.pivot_table(index='time', columns='status', values='f0_', fill_value=0)


pivot_df.head()


pivot_df.info()


pivot_df.describe()





status_columns = ['approved', 'denied', 'refunded', 'failed', 'processing', 'backend_reversed', 'reversed']
graph_df = pd.get_dummies(pivot_df.reset_index(), columns=['time'])

# Filter columns that contain 'time' (representing minutes and hours)
time_columns = [col for col in graph_df.columns if 'time_' in col]

# Create a new time column that combines the values of all 'time' columns
# To do this, we will iterate over each row and find the hour and minute that are True

graph_df['time'] = graph_df[time_columns].idxmax(axis=1).str.replace('time_', '').str.replace('h ', ':')

# Now we can create the interactive chart using the new 'time' column as the X-axis
fig = px.line(graph_df, x='time', y=status_columns,
              labels={'time': 'Time', 'value': 'Number of Transactions'},
              title='Number of Transactions by Status Over Time')

# show the graph
fig.show()









denied_values  = pivot_df['denied']

# Calcular os quartis
Q1_denied = np.percentile(denied_values, 25)  # Primeiro quartil (25%)
Q3_denied = np.percentile(denied_values, 75)  # Terceiro quartil (75%)

# Calcular o IQR (intervalo interquartil)
IQR_denied = Q3_denied - Q1_denied

# Calcular os limites para detectar outliers
alert_denied_behavior = Q3_denied + 1.5 * IQR_denied
alert_denied_behavior





reversed_values = pivot_df['reversed']

# Calcular os quartis
Q1_reversed = np.percentile(reversed_values, 25)  # Primeiro quartil (25%)
Q3_reversed = np.percentile(reversed_values, 75)  # Terceiro quartil (75%)

# Calcular o IQR (intervalo interquartil)
IQR_reversed = Q3_reversed - Q1_reversed

# Calcular os limites para detectar outliers
alert_denied_behavior = Q3_reversed + 1.5 * IQR_reversed
alert_denied_behavior





failed_values = pivot_df['failed']

# Calcular os quartis
Q1_failed = np.percentile(failed_values, 25)  # Primeiro quartil (25%)
Q3_failed = np.percentile(failed_values, 75)  # Terceiro quartil (75%)

# Calcular o IQR (intervalo interquartil)
IQR_failed = Q3_failed - Q1_failed

# Calcular os limites para detectar outliers
alert_failed_behavior = Q3_failed + 1.5 * IQR_failed
alert_failed_behavior





# Convert the 'time' column into dummy variables
time_dummies_df = pd.get_dummies(pivot_df.reset_index(), columns=['time'])

time_dummies_df.head(3)








# Set columns to delete
excluded_denied = ['time']

# Get the columns to scale, except the "time" column
columns_to_scale_denied = [column for column in time_dummies_df.columns if column not in excluded_denied]

# Scaledata
data_scaler_denied = time_dummies_df[columns_to_scale_denied].drop(columns=['denied'])

scaler_denied = StandardScaler().fit(data_scaler_denied)


denied_model = time_dummies_df.copy()

# Create features
X_denied = denied_model.drop(columns=['denied'])
y_denied = denied_model['denied']

# Split data into testing and training
X_train_denied, X_test_denied, y_train_denied, y_test_denied = train_test_split(X_denied, y_denied, test_size=0.2, random_state=42)

# Create the regresseion model
regression_model_denied = LinearRegression()

# Ajustar o modelo aos dados de treino
regression_model_denied.fit(X_train_denied, y_train_denied)


# joblib.dump(regression_model_denied, 'regression_model_denied.pkl')

joblib.dump((regression_model_denied, scaler_denied), 'model_and_scaler_denied.pkl')


# Fazer previsões nos dados de teste para "Denied"
y_denied_pred = regression_model_denied.predict(X_denied)

# Visualizar as previsões
y_denied_pred


y_denied_pred





# Set columns to delete
excluded_reversed = ['time']

# Get the columns to scale, except the "time" column
columns_to_scale_reversed = [column for column in time_dummies_df.columns if column not in excluded_reversed]

# Scale data
data_scaler_reversed = time_dummies_df[columns_to_scale_reversed].drop(columns=['reversed'])

scaler_reversed = StandardScaler().fit(data_scaler_reversed)


reversed_model = time_dummies_df.copy()

# Create features
X_reversed = reversed_model.drop(columns=['reversed'])
y_reversed = reversed_model['reversed']

# Split data into testing and training
X_train_reversed, X_test_reversed, y_train_reversed, y_test_reversed = train_test_split(X_reversed, y_reversed, test_size=0.2, random_state=42)

# Create the regresseion model
regression_model_reversed = LinearRegression()

# Ajustar o modelo aos dados de treino
regression_model_reversed.fit(X_train_reversed, y_train_reversed)


# scaler_reversed.feature_names_in_.sum()


# regression_model_reversed.feature_names_in_.sum()


# joblib.dump(regression_model_reversed, 'regression_model_reversed.pkl')
joblib.dump((regression_model_reversed, scaler_reversed), 'model_and_scaler_reversed.pkl')


# Fazer previsões nos dados de teste para "Denied"
y_reversed_pred = regression_model_reversed.predict(X_reversed)

# Visualizar as previsões
y_reversed_pred





excluded_failed = ['time']
# Get the columns to scale
columns_to_scale_failed  = [column for column in time_dummies_df.columns if column not in excluded_failed]
# Scale the data
data_scaler_failed  = time_dummies_df[columns_to_scale_failed].drop(columns=['failed'])

scaler_failed = StandardScaler().fit(data_scaler_failed)



# scaler_failed.feature_names_in_.sum()


failed_model = time_dummies_df.copy()

# Split the data into train and test sets
X_failed = failed_model.drop(columns=['failed'])
print("Colunas de X_failed antes do escalonamento:", X_failed.columns)

y_failed = failed_model['failed']
X_train, X_test, y_train, y_test = train_test_split(X_failed, y_failed, test_size=0.2, random_state=42)
# Create the linear regression model
regression_model_failed = LinearRegression()
# Fit the model to the training data
regression_model_failed.fit(X_train, y_train)



regression_model_denied.feature_names_in_.sum()
print("Colunas de X_failed antes do escalonamento:", X_failed.columns)



# joblib.dump(regression_model_failed, 'regression_model_failed.pkl')
joblib.dump((regression_model_failed, scaler_failed), 'model_and_scaler_failed.pkl')


regression_model_failed.coef_


# Make predictions on the test data
y_failed_pred = regression_model_failed.predict(X_failed)
y_failed_pred






transaction_df2 = pd.read_csv('transactions_2.csv')

transaction_df2.head(3)


pivot_df2 = transaction_df2.pivot_table(index='time', columns='status', values='count', fill_value=0)

pivot_df2.head()


pivot_df2.info()


pivot_df2.describe()


status_columns2 = ['approved', 'denied', 'refunded', 'failed', 'processing', 'backend_reversed', 'reversed']
graph_df2 = pd.get_dummies(pivot_df2.reset_index(), columns=['time'])

# Filter columns that contain 'time' (representing minutes and hours)
time_columns2 = [col for col in graph_df2.columns if 'time_' in col]

# Create a new time column that combines the values of all 'time' columns
# To do this, we will iterate over each row and find the hour and minute that are True

graph_df2['time'] = graph_df[time_columns].idxmax(axis=1).str.replace('time_', '').str.replace('h ', ':')

# Now we can create the interactive chart using the new 'time' column as the X-axis
fig = px.line(graph_df2, x='time', y=status_columns2,
              labels={'time': 'Time', 'value': 'Number of Transactions'},
              title='Number of Transactions by Status Over Time')

# show the graph
fig.show()









denied_values  = pivot_df2['denied']

# Calcular os quartis
Q1_denied = np.percentile(denied_values, 25)  # Primeiro quartil (25%)
Q3_denied = np.percentile(denied_values, 75)  # Terceiro quartil (75%)

# Calcular o IQR (intervalo interquartil)
IQR_denied = Q3_denied - Q1_denied

# Calcular os limites para detectar outliers
alert_denied_behavior = Q3_denied + 1.5 * IQR_denied
alert_denied_behavior





reversed_values = pivot_df2['reversed']

# Calcular os quartis
Q1_reversed = np.percentile(reversed_values, 25)  # Primeiro quartil (25%)
Q3_reversed = np.percentile(reversed_values, 75)  # Terceiro quartil (75%)

# Calcular o IQR (intervalo interquartil)
IQR_reversed = Q3_reversed - Q1_reversed

# Calcular os limites para detectar outliers
alert_denied_behavior = Q3_reversed + 1.5 * IQR_reversed
alert_denied_behavior





failed_values = pivot_df2['failed']

# Calcular os quartis
Q1_failed = np.percentile(failed_values, 25)  # Primeiro quartil (25%)
Q3_failed = np.percentile(failed_values, 75)  # Terceiro quartil (75%)

# Calcular o IQR (intervalo interquartil)
IQR_failed = Q3_failed - Q1_failed

# Calcular os limites para detectar outliers
alert_failed_behavior = Q3_failed + 1.5 * IQR_failed
alert_failed_behavior
