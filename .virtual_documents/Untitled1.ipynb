# Importando as bibliotecas necessárias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score


transactions_df = pd.read_csv('transactions_1.csv')

transactions_df.head(3)


# Pivotando os dados para que cada status seja uma coluna
pivot_df  = transactions_df.pivot_table(index='time', columns='status', values='f0_', fill_value=0)


pivot_df.head()


pivot_df.info()


pivot_df.describe()


# df_graph = pivot_df

# # Filtrar colunas que contêm 'time' (que representam os minutos e horas)
# time_columns = [col for col in df_graph.columns if 'time_' in col]

# # Para isso, vamos iterar sobre cada linha e encontrar a hora e minuto que são True
# df_graph['time'] = df_graph[time_columns].idxmax(axis=1).str.replace('time_', '').str.replace('h ', ':')

# # Agora podemos criar o gráfico interativo usando a nova coluna de 'time' como eixo X
# fig = px.line(df_graph, x='time', y=status_columns,
#               labels={'time': 'Time', 'value': 'Number of Transactions'},
#               title='Number of Transactions by Status Over Time')

# # Mostrar o gráfico interativo
# fig.show()



# Convert the 'time' column into dummy variables
time_dummies_df = pd.get_dummies(pivot_df.reset_index(), columns=['time'])

time_dummies_df.head(3)


# # Definindo o alvo como 'denied' e as features
# X = time_dummies_df.drop(columns=['denied'])  # Mantendo todas as colunas, exceto o alvo
# y = time_dummies_df['denied']

# # Dividindo o dataset em treino e teste
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # Criando e treinando o modelo de regressão linear
# model = LinearRegression()
# model.fit(X_train, y_train)
# # Fazendo previsões no conjunto de teste
# y_pred = model.predict(X_test)

# # Avaliando o modelo
# mse = mean_squared_error(y_test, y_pred)
# r2 = r2_score(y_test, y_pred)

# mse, r2



categorical_columns_failed  = ['time']
# Convert the categorical columns to dummy variables
general_transactions_model = pd.get_dummies(pivot_df, 'time')
# Get the columns to scale
columns_to_scale_failed  = [column for column in general_transactions_model.columns if column not in categorical_columns_failed]
# Scale the data
data_scaler_failed  = general_transactions_model[columns_to_scale_failed]
scaler_failed = StandardScaler().fit(data_scaler_failed)


feature_importance = model.coef_

feature_importance_df = pd.DataFrame({
    'Feature': X.columns,
    'Importance': feature_importance
})

feature_importance_df['Absolute Importance'] = np.abs(feature_importance_df['Importance'])
sorted_importance_df = feature_importance_df.sort_values(by='Absolute Importance', ascending=False)

sorted_importance_df.head(10)




